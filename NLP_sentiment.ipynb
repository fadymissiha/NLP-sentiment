{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9232840e",
   "metadata": {},
   "source": [
    "<h4>Part I: Research Question</h4>\n",
    "<p><b>A1. </b>Can we create and train a neural network model using NLP techniques to analyze the history of customers reviews and scores to forecast and predict customer sentiment is positive or negative?<p>\n",
    "<p><b>A2. </b>This study aims to prepare the history of customer reviews and scores and build and train the neural network model to predict and forecast customer sentiment and define positive or negative to understand the customer and improve the business by supporting the marketing process.\n",
    "<p><b>A3. </b>The study will use the TensorFlow Neural Networks, the sentiment analysis is one of the tasks in Natural Language Processing (NLP) techniques that will perform a text classification that can be trained to predict text sequences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85fa2254",
   "metadata": {},
   "source": [
    "[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7552959.svg)](https://doi.org/10.5281/zenodo.7552959)\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99f36a",
   "metadata": {},
   "source": [
    "<h4>Part II: Data Preparation</h4>\n",
    "<p><b>B.</b> The data preparation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10bced78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from dateutil.parser import parse\n",
    "import statsmodels.api as sm\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import callbacks\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import string\n",
    "import re\n",
    "import datetime\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1279a335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1EE2E3N7PW666</td>\n",
       "      <td>B000GFDAUG</td>\n",
       "      <td>Aaron L. Allen \"Orgazmo1009\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>CA Lewsi' review should be removed. he's revie...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Stupid</td>\n",
       "      <td>1202256000</td>\n",
       "      <td>02 6, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGZ8SM1BGK3CK</td>\n",
       "      <td>B000GFDAUG</td>\n",
       "      <td>Mind's Clay</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I truly love the humor of South Park. It's soc...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>\"More Moist Than Should Be\" Humor</td>\n",
       "      <td>1198195200</td>\n",
       "      <td>12 21, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2VHZ21245KBT7</td>\n",
       "      <td>B000GIOPK2</td>\n",
       "      <td>202_d \"202_d\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a cartoon series pitting eight cartoon...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Overall, really like the series.</td>\n",
       "      <td>1215388800</td>\n",
       "      <td>07 7, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACX8YW2D5EGP6</td>\n",
       "      <td>B000GIOPK2</td>\n",
       "      <td>Alexandra Stephens \"dreamgirl0922\"</td>\n",
       "      <td>[11, 13]</td>\n",
       "      <td>Yeah drawn together is great when it comes to ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Crude cartoon humor...Check</td>\n",
       "      <td>1185840000</td>\n",
       "      <td>07 31, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A9RNMO9MUSMTJ</td>\n",
       "      <td>B000GIOPK2</td>\n",
       "      <td>Andre Villemaire</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>Seems like today's generation is getting reven...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>not bad...</td>\n",
       "      <td>1281052800</td>\n",
       "      <td>08 6, 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                        reviewerName   helpful  \\\n",
       "0  A1EE2E3N7PW666  B000GFDAUG        Aaron L. Allen \"Orgazmo1009\"    [0, 0]   \n",
       "1   AGZ8SM1BGK3CK  B000GFDAUG                         Mind's Clay    [1, 1]   \n",
       "2  A2VHZ21245KBT7  B000GIOPK2                       202_d \"202_d\"    [0, 0]   \n",
       "3   ACX8YW2D5EGP6  B000GIOPK2  Alexandra Stephens \"dreamgirl0922\"  [11, 13]   \n",
       "4   A9RNMO9MUSMTJ  B000GIOPK2                    Andre Villemaire    [0, 2]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  CA Lewsi' review should be removed. he's revie...      5.0   \n",
       "1  I truly love the humor of South Park. It's soc...      5.0   \n",
       "2  This is a cartoon series pitting eight cartoon...      4.0   \n",
       "3  Yeah drawn together is great when it comes to ...      4.0   \n",
       "4  Seems like today's generation is getting reven...      2.0   \n",
       "\n",
       "                             summary  unixReviewTime   reviewTime  \n",
       "0                             Stupid      1202256000   02 6, 2008  \n",
       "1  \"More Moist Than Should Be\" Humor      1198195200  12 21, 2007  \n",
       "2   Overall, really like the series.      1215388800   07 7, 2008  \n",
       "3        Crude cartoon humor...Check      1185840000  07 31, 2007  \n",
       "4                         not bad...      1281052800   08 6, 2010  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert and load the gz file to DataFrame\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "    \n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "    #if i == 1000 : break  # to run for first 1000 just for the quick test\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('reviews_Amazon_Instant_Video.json.gz')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1370e626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>583933.000000</td>\n",
       "      <td>5.839330e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.316185</td>\n",
       "      <td>1.377140e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.163706</td>\n",
       "      <td>3.257195e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.354528e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.368835e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.387325e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.394669e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.406074e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime\n",
       "count  583933.000000    5.839330e+05\n",
       "mean        4.316185    1.377140e+09\n",
       "std         1.163706    3.257195e+07\n",
       "min         1.000000    9.354528e+08\n",
       "25%         4.000000    1.368835e+09\n",
       "50%         5.000000    1.387325e+09\n",
       "75%         5.000000    1.394669e+09\n",
       "max         5.000000    1.406074e+09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d0e18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Review_in_words</th>\n",
       "      <th>Nostop_words</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>CA Lewsi  review should be removed  he s revie...</td>\n",
       "      <td>[CA, Lewsi, review, should, be, removed, he, s...</td>\n",
       "      <td>[ca, lewsi, review, removed, reviewing, episod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I truly love the humor of South Park  It s soc...</td>\n",
       "      <td>[I, truly, love, the, humor, of, South, Park, ...</td>\n",
       "      <td>[i, truly, love, humor, south, park, it, socia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>This is a cartoon series pitting eight cartoon...</td>\n",
       "      <td>[This, is, a, cartoon, series, pitting, eight,...</td>\n",
       "      <td>[this, cartoon, series, pitting, eight, cartoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Yeah drawn together is great when it comes to ...</td>\n",
       "      <td>[Yeah, drawn, together, is, great, when, it, c...</td>\n",
       "      <td>[yeah, drawn, together, great, comes, crude, h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Seems like today s generation is getting reven...</td>\n",
       "      <td>[Seems, like, today, s, generation, is, gettin...</td>\n",
       "      <td>[seems, like, today, generation, getting, reve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I dont agree with the reviewer who says the sh...</td>\n",
       "      <td>[I, dont, agree, with, the, reviewer, who, say...</td>\n",
       "      <td>[i, dont, agree, reviewer, says, show, wears, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Apparently I m one of the few who really think...</td>\n",
       "      <td>[Apparently, I, m, one, of, the, few, who, rea...</td>\n",
       "      <td>[apparently, i, one, really, thinks, drawn, to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I liked this product  I am a big fan of Drawn ...</td>\n",
       "      <td>[I, liked, this, product, I, am, a, big, fan, ...</td>\n",
       "      <td>[i, liked, product, i, big, fan, drawn, togeth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>the show  it is really funny  it is a good sho...</td>\n",
       "      <td>[the, show, it, is, really, funny, it, is, a, ...</td>\n",
       "      <td>[show, really, funny, good, show, get, dvd, i,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>People who like cartoons must be thankful for ...</td>\n",
       "      <td>[People, who, like, cartoons, must, be, thankf...</td>\n",
       "      <td>[people, like, cartoons, must, thankful, dvds,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                         reviewText  \\\n",
       "0    5.0  CA Lewsi  review should be removed  he s revie...   \n",
       "1    5.0  I truly love the humor of South Park  It s soc...   \n",
       "2    4.0  This is a cartoon series pitting eight cartoon...   \n",
       "3    4.0  Yeah drawn together is great when it comes to ...   \n",
       "4    2.0  Seems like today s generation is getting reven...   \n",
       "5    5.0  I dont agree with the reviewer who says the sh...   \n",
       "6    5.0  Apparently I m one of the few who really think...   \n",
       "7    4.0  I liked this product  I am a big fan of Drawn ...   \n",
       "8    5.0  the show  it is really funny  it is a good sho...   \n",
       "9    5.0  People who like cartoons must be thankful for ...   \n",
       "\n",
       "                                     Review_in_words  \\\n",
       "0  [CA, Lewsi, review, should, be, removed, he, s...   \n",
       "1  [I, truly, love, the, humor, of, South, Park, ...   \n",
       "2  [This, is, a, cartoon, series, pitting, eight,...   \n",
       "3  [Yeah, drawn, together, is, great, when, it, c...   \n",
       "4  [Seems, like, today, s, generation, is, gettin...   \n",
       "5  [I, dont, agree, with, the, reviewer, who, say...   \n",
       "6  [Apparently, I, m, one, of, the, few, who, rea...   \n",
       "7  [I, liked, this, product, I, am, a, big, fan, ...   \n",
       "8  [the, show, it, is, really, funny, it, is, a, ...   \n",
       "9  [People, who, like, cartoons, must, be, thankf...   \n",
       "\n",
       "                                        Nostop_words  Sentiment  \n",
       "0  [ca, lewsi, review, removed, reviewing, episod...          1  \n",
       "1  [i, truly, love, humor, south, park, it, socia...          1  \n",
       "2  [this, cartoon, series, pitting, eight, cartoo...          1  \n",
       "3  [yeah, drawn, together, great, comes, crude, h...          1  \n",
       "4  [seems, like, today, generation, getting, reve...          0  \n",
       "5  [i, dont, agree, reviewer, says, show, wears, ...          1  \n",
       "6  [apparently, i, one, really, thinks, drawn, to...          1  \n",
       "7  [i, liked, product, i, big, fan, drawn, togeth...          1  \n",
       "8  [show, really, funny, good, show, get, dvd, i,...          1  \n",
       "9  [people, like, cartoons, must, thankful, dvds,...          1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove nulls\n",
    "df = df.dropna()\n",
    "\n",
    "Eng_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "df_selected = pd.DataFrame()\n",
    "df_selected['Score'] = df['overall']\n",
    "\n",
    "# replacing our Non-English characters by space\n",
    "df_selected['reviewText'] = df['reviewText'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "\n",
    "# split in words\n",
    "df_selected['Review_in_words'] = df['reviewText'].apply(lambda x: re.split('\\W+', x))\n",
    "\n",
    "# Avoid the stop words and convert all words to lower case.\n",
    "df_selected['Nostop_words'] = \\\n",
    "    df_selected['Review_in_words'].apply(lambda x: [word.lower() for word in x if word not in Eng_stopwords])\n",
    "\n",
    "# classifying the score to positive Sentiment if score 5, 4 or 3.\n",
    "df_selected['Sentiment'] = df['overall'].apply(lambda x: 1 if x in [3, 4, 5] else 0)\n",
    "\n",
    "df_selected.head(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39af1cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>578419.000000</td>\n",
       "      <td>578419.000000</td>\n",
       "      <td>578419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.316831</td>\n",
       "      <td>0.897011</td>\n",
       "      <td>32.205944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.162447</td>\n",
       "      <td>0.303945</td>\n",
       "      <td>46.725136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3252.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Score      Sentiment      num_words\n",
       "count  578419.000000  578419.000000  578419.000000\n",
       "mean        4.316831       0.897011      32.205944\n",
       "std         1.162447       0.303945      46.725136\n",
       "min         1.000000       0.000000       0.000000\n",
       "25%         4.000000       1.000000      15.000000\n",
       "50%         5.000000       1.000000      19.000000\n",
       "75%         5.000000       1.000000      32.000000\n",
       "max         5.000000       1.000000    3252.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count words per review\n",
    "df_selected['num_words'] = df_selected['Nostop_words'].apply(lambda x: len(x))\n",
    "\n",
    "# join words to be statement\n",
    "df_selected['words'] = df_selected['Nostop_words'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "df_selected.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32af6d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Number of words:  3252\n"
     ]
    }
   ],
   "source": [
    "max_num_words = df_selected['num_words'].values.max()\n",
    "print('Max Number of words: ', max_num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a9bb5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for vocabulary, tokenizer, Pad sentences and the model\n",
    "\n",
    "# maximum number of unique words used in our model\n",
    "vocab_size = 60000 \n",
    "\n",
    "# Embedded words into 16 dimensions\n",
    "embedding_dim = 16\n",
    "\n",
    "# Maximum length per review\n",
    "max_length = 100\n",
    "\n",
    "# \"post\"-truncated after 100 to the end of the review\n",
    "trunc_type = 'post'\n",
    "\n",
    "# \"Out of Vocabulary\" (OOV) to replace any unknown words\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# if review less than 100 padding applied until the end of the review\n",
    "padding_type = 'post'\n",
    "# Instantiate tokenizer object\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
    "\n",
    "# Fit tokenizer to training set\n",
    "tokenizer.fit_on_texts(df_selected['words'])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Pad sentences\n",
    "sequences = tokenizer.texts_to_sequences(df_selected['words'])\n",
    "padded = pad_sequences(sequences, maxlen = max_length, truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a704a1",
   "metadata": {},
   "source": [
    "<h4>Tokenization</h4>\n",
    "<p>Tokenization is a key aspect of working with text data and is a common task in Natural Language Processing (NLP).\n",
    "Tokenization is separating a piece of text into smaller units called tokens. Tokens can be either word, characters, or sub-words. Hence, tokenization can be broadly classified into three types word, characters, or sub-words. (Analytics Vidhya. 2022)\n",
    "    \n",
    "<h4>Padding process</h4>\n",
    "<p>To prepare the data for the NLP model, the padding process standardizes the lengths of the sentences by adding pads at the beginning or end of each sentence to be in the same length, in our code using the ‘Post’ option to add the pads at the end of a sentence.\n",
    "\n",
    "<h4>Sentiment Categories</h4>\n",
    "<p>Simplified the categories of Sentiment in just two types (1 mean positive Sentiment verified by the scores (3, 4, or 5) and 0 mean negative sentiment verified by the scores (1, or 2). \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41d02c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabularies count: 163860\n",
      "\n",
      "Example for padded sequence:\n",
      "\n",
      "\t\"very adult humor cutting sarcasm dry take reality shows least \"\n",
      "\n",
      "\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0  122  643  186 2745 4327 1659  159  288\n",
      "   30  237]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_counter = str(len(word_index))\n",
    "print('The vocabularies count: ' +  vocabulary_counter)\n",
    "\n",
    "print('\\nExample for padded sequence:\\n\\n\\t\\\"' + str(df_selected['words'][10]) + '\\\"\\n\\n')\n",
    "\n",
    "print(str(padded[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ee62dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the extra and useless columns.\n",
    "df_clean = df_selected.drop(['Review_in_words', 'Nostop_words', 'num_words', 'reviewText'], axis = 1)\n",
    "\n",
    "# Save copy of Cleaned dataset\n",
    "df_clean.to_csv('prepared_clean_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data to 80% training Data and 20% test data\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(padded, df_selected['Sentiment'], test_size=0.20, random_state=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ae72c",
   "metadata": {},
   "source": [
    "<h4>Part III:  Network Architecture</h4>\n",
    "<p>The Network used TensorFlow to create Keras model with the following Sequential:\n",
    "<ol>\n",
    "    <li>Embedding layer to defines the parameters like vocabulary size, dimension, and maximum length for the input and the results will be 960000 parameters\n",
    "    <li>GlobalAveragePooling1D layer to convert the vector to one dimension and the results will be no parameters\n",
    "    <li>Hidden layer applies the “relu” a rectified linear activation function and has 20 density and the results will be 340 parameters.\n",
    "    <li>Hidden layer applies the “relu” a rectified linear activation function and has 10 density and the results will be 210 parameters.\n",
    "    <li>Output and final layer apply the “relu” a rectified linear activation function and have 1 density and the results will be 11 parameters.\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07a4e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length), # Embedding layer where parameters are defined\n",
    "    tf.keras.layers.GlobalAveragePooling1D(), # Convert vector to one dimension\n",
    "    tf.keras.layers.Dense(20, activation = 'relu'), # Hidden layer\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'), # Hidden layer\n",
    "    tf.keras.layers.Dense(1, activation = 'relu') # Output Layer \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba3d5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "09d8156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 16)           960000    \n",
      "                                                                 \n",
      " global_average_pooling1d_8   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                340       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 960,561\n",
      "Trainable params: 960,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a84f2773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14461/14461 [==============================] - 136s 9ms/step - loss: 0.2477 - accuracy: 0.9050 - val_loss: 0.2325 - val_accuracy: 0.9335\n",
      "Epoch 2/20\n",
      "14461/14461 [==============================] - 140s 10ms/step - loss: 0.1934 - accuracy: 0.9374 - val_loss: 0.1939 - val_accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "# number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs = num_epochs,\n",
    "                    callbacks = EarlyStopping(monitor = 'val_loss'), \n",
    "                    validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adcb7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7231/7231 [==============================] - 72s 10ms/step - loss: 0.1892 - accuracy: 0.9269 - val_loss: 0.1862 - val_accuracy: 0.9399\n",
      "Epoch 2/20\n",
      "7231/7231 [==============================] - 68s 9ms/step - loss: 0.1832 - accuracy: 0.9373 - val_loss: 0.1910 - val_accuracy: 0.9409\n",
      "Epoch 3/20\n",
      "7231/7231 [==============================] - 69s 10ms/step - loss: 0.1592 - accuracy: 0.9478 - val_loss: 0.1914 - val_accuracy: 0.9403\n",
      "Epoch 4/20\n",
      "7231/7231 [==============================] - 69s 10ms/step - loss: 0.1579 - accuracy: 0.9465 - val_loss: 0.2128 - val_accuracy: 0.9399\n",
      "Epoch 5/20\n",
      "7231/7231 [==============================] - 69s 10ms/step - loss: 0.1622 - accuracy: 0.9473 - val_loss: 0.2180 - val_accuracy: 0.9407\n",
      "Epoch 6/20\n",
      "7231/7231 [==============================] - 70s 10ms/step - loss: 0.1789 - accuracy: 0.9377 - val_loss: 0.2462 - val_accuracy: 0.9403\n"
     ]
    }
   ],
   "source": [
    "# Fit model tuning by extra parameters: \n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs = num_epochs,\n",
    "                    callbacks = EarlyStopping(monitor = 'val_loss', \n",
    "                                              mode =\"min\", \n",
    "                                              patience = 5, \n",
    "                                              restore_best_weights = True), \n",
    "                    batch_size=64,\n",
    "                    validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c09f20",
   "metadata": {},
   "source": [
    "<h4>Justify Hyperparameters</h4>\n",
    "<p>The Network used TensorFlow to create Keras model with the following Sequential:\n",
    "<ul>\n",
    "    <li>Activation Function: use the “relu” a rectified linear activation function for the two hidden layers, which is commonly used in most of the Networks because easy in the train and has better performance.\n",
    "    <li>Number of nodes per layer: during practice multiple tests and because the dataset has 578419 rows, I found the best accuracy around 95% comes with 20, 10 densities for hidden layers.\n",
    "    <li>Loss function: apply 'binary_crossentropy' which is perfect for the binary classification problems.\n",
    "    <li>Optimizer: “Adam” which uses little memory and is suited for large problems.\n",
    "    <li>Stopping Criteria: “EarlyStopping” which stops the training if the performance going to degrade per Epoch, avoiding overdraft.\n",
    "    <li>Evaluation Metric: “Accuracy” is used in evaluating the model comparing the accuracy of the results.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8f4d1",
   "metadata": {},
   "source": [
    "<h4>Part IV:  Model Evaluation</h4>\n",
    "\n",
    "<b>stopping criteria:</b>\n",
    "<p>Its callback function during the model fitting to measure the improvement changes per epoch to not continue if the loss degrades to avoid running the rest of epochs. The stopping criteria function used in the study is “EarlyStopping” which stops running the rest of the epoch in the first try after the second epoch and in the second try in epoch 6.</p>\n",
    "    \n",
    "    \n",
    "<b>Fitness of the model:</b>\n",
    "<p>For the best fit and avoid overfitting the study used the EarlyStopping callback function as Stopping criteria which stopped with epoch 6 as the optimal number of epochs.</p>\n",
    "    \n",
    "    \n",
    "<b>Predictive Accuracy:</b>    \n",
    "<p>Using the model evaluation function, the training data accuracy results are around 95 % which reflects confidence in the model accuracy.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ce271af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14461/14461 [==============================] - 12s 848us/step - loss: 0.1546 - accuracy: 0.9460\n",
      "\n",
      "Accuracy: 94.601661\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('\\nAccuracy: %f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "02921570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizations of the model’s training process\n",
    "\n",
    "epochs=range(len(history.history['accuracy']))\n",
    "\n",
    "plt.plot(epochs, history.history['accuracy'], 'r', 'Train Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'b', 'Test Accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5233dc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEICAYAAACXo2mmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUOklEQVR4nO3de7RmdX3f8fdnzhkYYIYZGEbuwygqtJjGxpFERUuRRok30suKVNpq0rLsqjUkXQ3UlRhMljEm1KhJVxtjEk3BWA3JatQ0lmVQoqLIRC4CQRShXMJluMgMl2HmnG//2Pt4HoZzn985D3PO+7XWb+3fs/d+fvu357I/z/7t/Tw7VYUkSS2sGnYHJEnLh6EiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVrXhJ/k+Sf/Ms6MdFSS4Zdj+kfWGoaL+UZOdAGU/yxMDrt8ynrao6q6o+vlh93VdJ3jKwb0/0+/uD/V9Ae1uSVJLRGdYx4LQghor2S1W1dqIA/w94w8C8SyfWm+nAub+oqksH9vUs4J699l961jBUtKwkOT3JXUkuSHIv8IdJDkvy2SQPJHm4rx838J4vJvm3ff2tSb6c5OJ+3e8lOWuG7V2Y5LtJdiS5KclPDiybsa0kz03ypf69lwNHLGB/j0lyWb9v30vyzoFlpya5JsmjSe5L8oF+0ZX99JH+bOdl89zmG5PcmOSR/s/u7w0suyDJ3f0+3ZLk1bP0RcuMoaLl6CjgcOAE4Dy6f+d/2L/eDDwB/M4M7/9R4Ba6g/xvAL+fJNOs+13glcB64D3AJUmOnmNbnwC29ct+FZjXdZ0kq4DPANcBxwKvBs5P8pp+lQ8BH6qqQ4ETgU/181/VTzf0ZztXzWObLwT+GDgf2AT8BfCZJAckOQl4B/DSqloHvAa4fZa+aJkxVLQcjQO/XFW7quqJqnqwqi6rqseragfwXuAfzfD+O6rq96pqDPg4cDRw5FQrVtWnq+qeqhqvqv8F3AqcOltbSTYDLwV+qe/nlXQBMR8vBTZV1a9U1VNVdRvwe8Cb++W7gecnOaKqdlbV1+bZ/lR+CvhcVV1eVbuBi4GDgJcDY8CBwN9Psrqqbq+q7y5iX/QsZKhoOXqgqp6ceJHk4CS/m+SOJI/SDf9sSDIyzfvvnahU1eN9dcprF0n+dZJr+6GgR4AX8fRhrOnaOgZ4uKoeG1j3jrnt3g+cABwzse1+++9iMgB/Bngh8LdJvpHk9fNsfyrHDPazqsaBO4Fjq+o7dGcwFwH3J/lkkmMWsS96FjJUtBzt/dPb/wk4CfjRfvhlYvhnuiGtOUlyAt2ZwTuAjVW1AfjWHNv9O+CwJIcMzNs8zy7cCXyvqjYMlHVV9RMAVXVrVZ0DPAd4P/An/fb25afJ76ELMwD6obzjgbv7bX6iqk7r16l+uzP1RcuMoaKVYB3ddZRHkhwO/HKjdicO0A8AJHkb3ZnKrKrqDuAa4D399YjTgDfMc/tXA4/2F8cPSjKS5EVJXtr359wkm/qziUf694z1/R0HnjdL+6uSrBkoB9JdC3ldklcnWU0X2LuAryY5KckZ/XpP0v2Zj83SFy0zhopWgg/SjftvB74G/GWLRqvqJuC/AlcB9wE/BHxlHk38S7oL+Q/RBd0fzXP7Y3RB9GLge3T791G6mwYAXgvcmO67LB8C3lxVT/bDcO8FvtIPm/3YNJs4hy4YJsp3q+oW4Fzgt/vtvYHudu6n6K6n/Ho//166s5J3zdSX+eyv9g/xIV2SpFY8U5EkNWOoSJKaMVQkSc0YKpKkZvb7H9vbF0cccURt2bJl2N2QpP3Ktm3btlfVpqmWrehQ2bJlC9dcc82wuyFJ+5Uk0/76g8NfkqRmDBVJUjOGiiSpGUNFktSMoSJJambed38l2Qh8oX95FJO/egpwav/DcjO9/3Tgqar66hTL3gpsrap3zLdfkqThm3eoVNWDdL+KSpKLgJ1VdfE8mjgd2Ak8I1QkSfu3JsNfSV6S5EtJtiX5/MQzupO8M8lNSa7vnwK3BXg78HP90/JeOcf2fz7Jt/pyfj/vkCSfS3JdP/+n+vm/PrDN+YSdJGkftfjyY+ierfCmqnqgP7i/F/hp4ELguVW1K8mGqnokyf9gHmc3SV4CvI3uuRMBvp7kS3QPGLqnql7Xr7e+fwDTTwInV1Ul2TBFe+cB5wFs3jzfB+1JkmbS4kzlQLqn3V2e5FrgF4Hj+mXXA5cmORfYs8D2TwP+rKoeq6qdwJ8CrwRuAM5M8v4kr6yq7wOP0j1x7qNJ/inw+N6NVdVHqmprVW3dtGnKXxmQJC1Qi1AJcGNVvbgvP1RVP94vex3w34CXANuSLOTMaMrnfVfVt/t2bwDel+TdVbUHOBW4DDibRk/4kyTNTYtQ2QVsSvIygCSrk5ySZBVwfFVdAfwCsAFYC+yge2b4XF0JnJ3k4CSH0A1v/XWSY4DHq+oS4GLgR5KsBdZX1V8A59PfUCBJWhotrqmMA/8c+HCS9X2bHwS+DVzSzwvwW/01lc8Af5LkTcB/rKq/3qu9tyY5e+D1jwEfA67uX3+0qr6Z5DXAbyYZB3YD/54urP53kjX9Nn+uwf5JkuZoRT+jfuvWreWvFEvS/CTZVlVbp1rmN+olSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWpmdNgdkCQtnqeegvvumyz33ttNTz0Vzjyz/fYMFUnaz+zeDfffPxkQg2Gx97yHH566jQsuMFQkadnas6cLiulCYjAsHnxw6jbWrYOjjoIjj4RTToEzzujqE/MmpkceCWvWLM5+GCqStEjGxuCBB+Z2RvHgg1D1zDbWrp0MhJNPhtNPnwyGvcPioIOWfBefwVCRpHkYG4Pt22cPifvu6wJlqqA4+ODJIHjBC+C0055+FjFYP+SQpd/HfWGoSFrxxse7M4XZhp3uvbcLivHxZ7Zx0EGTgfC858HLX/7MgJior1279Pu4VAwVSXNS1Y3779799Ol09dmWt2xrX7f1/e93ZyB7W7NmMhBOOKG7Y2qqkDjqqC4okqX/e3m2MVSkZWzXLnjooe4OoIcemiyDr/de9thjUx98p/p0vhRGRmD1ahgdnZxOV9973oEHzrx8or5+/dRhceihBsV8GSrSs1wV7NgxfSjM9Prxx6dvd9UqOOwwOPzwrhxxRDe+v3bt/A/e+7LuTMtHRjyo728MFWmJ7N49ebCfayhM1Kcamplw0EGTwXDYYXDiiU9/PVHf+/W6dV2wSC0ZKtI8VHXDQwsJhh07pm83gQ0bnn7g37Jl9mA47LDF+76BtBCGykI88ADcfHN3fj6fMsePhRMXRBejjI3t2/sH+7h3fap5i11f7O1MXJMYDIndu5nWAQfAxo2TB/7Nm+GHf3j6UJh4vX59N9Qj7e8MlQX42u9ex2//0n3sYXQBZTV7MlBnlD2MTC6vEcYZ/tFlZKQYHYHR0frBGPfIaMjAAPdEdXDMe7b6Yq27WNs44IDuwH/ssbMHw+GHd0NRXgPQSmaoLMDDJ27l6mMPYHTV+GTJOKOrxhjNGKMZ5+BM1PcwysR0F6M8NhAxuxmtPYzW7r7el/GJ6VNTl7FdjI7vYnSsr+95kpGxgfkLjLvRH0TcGBkDxoCn9tr5gw/urujOtWzc2B2ZJQ3Xrl3w6KOTZePG7lS6MUNlAc46ZwO3njPsXkxjfHzyHtDW5Yknum+Ibd8+WW67rZs+8sj0fTr00JlDZ+95hx/enRpJK93ERbzBMJiq7Ngx+zpP7fUJ8cIL4X3va95l/+cuN6tWdWcGS312sHt3d8FhMHCmKvffDzfd1NV37py+vcMOm98Z0YYN3sqkZ489e+Z2oJ9tnR075vYFoTVrug9vg2Xz5mfOGywnn7wou26oqI3Vqye/OTZXTz75zDOfqcqdd8I3v9ndILFr19RtrVo19VnPTGXdOi+AaFLVM4eIFhoGM31BaNC6dc882B9zzNQhMNW6E/OfRUPMhoqGZ82a7gr4scfObf2q7j/rbCG0fTvceitcdVVXH7xtbdDq1XMPnsGyatUz5y1mWertwdNvFdx7OtOyxZou9jYef7wLg5lu7ZswMtLdrjd4YH/Oc+D5z589AAbL2rXL8uzaUNH+I+l+svWQQ7ofYpqLqu5gMZcguuGGbjrdb5Br6axa1R28R0dnn860bPXq7pa8mdoYGeluQJktBCbKmjWe4c7AUNHylnSfKtev775qPhdjY92NB9u3d8McVZNlfPzpr5eqLOV2YfaD9VwO9vsy9aC93zJUpL2NjHTXZzZuHHZPpP3O8hvQkyQNjaEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqRlDRZLUjKEiSWpmxlBJsjHJtX25N8ndA68PmOW9W5N8eD6dSXJ7kiPm8x5J0rPH6EwLq+pB4MUASS4CdlbVxRPLk4xW1Z5p3nsNcE2znkqSnvXmPfyV5GNJPpDkCuD9SU5N8tUk3+ynJ/XrnZ7ks339oiR/kOSLSW5L8s55bO+EJF9Icn0/3dzP/xdJvpXkuiRX9vNOSXJ1fyZ1fZIXzHf/JEkLN+OZygxeCJxZVWNJDgVeVVV7kpwJ/Brwz6Z4z8nAPwbWAbck+e9VtXsO2/od4I+q6uNJfhr4MHA28G7gNVV1d5IN/bpvBz5UVZf2w3MjezeW5DzgPIDNmzfPfY8lSbNa6IX6T1fVWF9fD3w6ybeA3wJOmeY9n6uqXVW1HbgfOHKO23oZ8Im+/j+B0/r6V4CPJfl3TIbHVcC7klwAnFBVT+zdWFV9pKq2VtXWTZs2zbELkqS5WGioPDZQ/1Xgiqp6EfAGYM0079k1UB9j4WdJBVBVbwd+ETgeuDbJxqr6BPBG4Ang80nOWOA2JEkL0OKW4vXA3X39rQ3a29tXgTf39bcAXwZIcmJVfb2q3g1sB45P8jzgtqr6MPDnwD9YhP5Ikqax0LOFQb8BfDzJzwN/1aC965OM9/VPAe8E/iDJfwYeAN7WL/vN/kJ8gC8A1wEXAucm2Q3cC/xKg/5IkuYoVTXsPgzN1q1b65prvOtZkuYjybaq2jrVMr9RL0lqxlCRJDVjqEiSmjFUJEnNrOgL9UkeAO5Y4NuPoLuVeSVxn1cG93ll2Jd9PqGqpvz2+IoOlX2R5Jrp7n5YrtznlcF9XhkWa58d/pIkNWOoSJKaMVQW7iPD7sAQuM8rg/u8MizKPntNRZLUjGcqkqRmDBVJUjOGygIkeW2SW5J8J8mFw+7PYusfBX1//yC2FSHJ8UmuSHJzkhuT/Oyw+7TYkqzpH8d9Xb/P7xl2n5ZCkpH+ceifHXZflkKS25Pc0D92vfkv6npNZZ6SjADfBv4JcBfwDeCcqrppqB1bREleBeyke6zzi4bdn6WQ5Gjg6Kr6myTrgG3A2cv87znAIVW1M8lqumcX/WxVfW3IXVtU/WM7tgKHVtXrh92fxZbkdmBr/xTe5jxTmb9Tge9U1W1V9RTwSeBNQ+7ToqqqK4GHht2PpVRVf1dVf9PXdwA3A8cOt1eLqzo7+5er+7KsP3UmOQ54HfDRYfdluTBU5u9Y4M6B13exzA82K12SLcA/BL4+5K4sun4o6FrgfuDyqlru+/xB4BeA8VnWW04K+L9JtiU5r3Xjhsr8ZYp5y/rT3EqWZC1wGXB+VT067P4stqoaq6oXA8cBpyZZtsOdSV4P3F9V24bdlyX2iqr6EeAs4D/0w9vNGCrzdxdw/MDr44B7htQXLaL+usJlwKVV9afD7s9SqqpHgC8Crx1uTxbVK4A39tcYPgmckeSS4XZp8VXVPf30fuDP6Ib0mzFU5u8bwAuSPDfJAcCbgT8fcp/UWH/R+veBm6vqA8Puz1JIsinJhr5+EHAm8LdD7dQiqqr/UlXHVdUWuv/Hf1VV5w65W4sqySH9jSckOQT4caDpXZ2GyjxV1R7gHcDn6S7efqqqbhxurxZXkj8GrgJOSnJXkp8Zdp+WwCuAf0X36fXavvzEsDu1yI4GrkhyPd2Hp8urakXcZruCHAl8Ocl1wNXA56rqL1tuwFuKJUnNeKYiSWrGUJEkNWOoSJKaMVQkSc0YKpKkZgwVSVIzhookqZn/D+EcBldWQ7TjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], 'r', 'Train Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'b', 'Test Loss')\n",
    "plt.title('Train and Test Loss')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce598e3",
   "metadata": {},
   "source": [
    "<h4>Part V:  Summary and Recommendations</h4>\n",
    "\n",
    "<b>Functionality:</b>\n",
    "\n",
    "<p>The study creates and trains a neural network to understand the customer review text to predict Sentiment, classifying positive or negative sentiment based on the words coming in the customer review text. Built the neural network model by sequential of five layers includes two hidden layers compile with “Binary Crossentropy” loss function optimizes by “Adam” evaluated by “accuracy” metrics and fitted by separated training data and validated by testing data. </p>\n",
    "\n",
    "<b>Recommendedations:</b> \n",
    "    \n",
    "<p>The decision-makers could use the study to understand the customer’s sentiments and predict the customer’s sentiments and classify and filter the customer’s review in the form which could support the marketing activities and improve the customer’s satisfaction.\n",
    "<p>\n",
    "The study accuracy results around 95% which reflects confidence in the model accuracy and the data analyst could run more tests on more data to improve the model results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8aed6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in HDF5 file\n",
    "model.save('SENTIMENT_model_20220120.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a52631",
   "metadata": {},
   "source": [
    "<b>Acknowledge Sources:</b>\n",
    "<p>Analytics Vidhya. (2022, Jan. 19) Time Series Analysis. [Web Site].  Retrieved from <a href=\"https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/\">https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/</a>\n",
    "\n",
    "<p>DataCamp (2022, Jan. 19) Sentiment Analysis Nuts and Bolts. [Web Site].  Retrieved from <a href=\"https://campus.datacamp.com/courses/sentiment-analysis-in-python/sentiment-analysis-nuts-and-bolts?ex=1\">https://campus.datacamp.com/courses/sentiment-analysis-in-python/sentiment-analysis-nuts-and-bolts?ex=1</a>\n",
    "\n",
    "<p>keras. (2022, Jan. 19) Text classification from scratch. [Web Site].  Retrieved from <a href=\"https://keras.io/examples/nlp/text_classification_from_scratch/\">https://keras.io/examples/nlp/text_classification_from_scratch/</a>\n",
    "\n",
    "<p>Towards. (2022, Jan. 19) Various Optimization Algorithms For Training Neural Network. [Web Site].  Retrieved from <a href=\"https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6\">https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6</a>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d1958",
   "metadata": {},
   "source": [
    "<b>Web Sources:</b>\n",
    "    \n",
    "<p>kavita. (2022, Jan. 18) How to Use Tfidftransformer & Tfidfvectorizer. [Web Site].  Retrieved from <a href=\"https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.YeZZjf7MKUk\">https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.YeZZjf7MKUk</a>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300facb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
